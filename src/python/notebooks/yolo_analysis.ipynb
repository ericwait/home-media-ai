{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Object Detection Analysis\n",
    "\n",
    "This notebook runs YOLO object detection on images filtered by date range and analyzes the results.\n",
    "It serves as a test bed for features that will eventually be integrated into the database.\n",
    "\n",
    "## Features\n",
    "- Filter images by date range and originals only\n",
    "- Run YOLOv8 object detection on filtered images\n",
    "- Build comprehensive DataFrame with all detection metadata\n",
    "- Visualize sample detections with bounding boxes\n",
    "- Generate summary statistics and analysis\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Set your parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ==========================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Date range for filtering images\n",
    "START_DATE = datetime(2024, 1, 1)\n",
    "END_DATE = datetime(2024, 6, 30)\n",
    "\n",
    "# YOLO model configuration\n",
    "YOLO_MODEL = 'yolov8x-seg.pt'  # Segmentation model - provides pixel-level masks + bounding boxes\n",
    "                                # Options: yolov8n-seg, yolov8s-seg, yolov8m-seg, yolov8l-seg, yolov8x-seg\n",
    "                                # (n=fastest/smallest, x=slowest/most accurate)\n",
    "CONFIDENCE_THRESHOLD = 0.25  # Minimum confidence for detections (0.0 - 1.0)\n",
    "IOU_THRESHOLD = 0.45  # IoU threshold for NMS (non-maximum suppression)\n",
    "\n",
    "# Processing options\n",
    "MAX_IMAGES = None  # Set to a number to limit processing (None = process all)\n",
    "RESIZE_FOR_YOLO = 1280  # Resize images to this size for YOLO (standard is 640)\n",
    "\n",
    "# Optional additional filters (set to None to disable)\n",
    "MIN_RATING = None  # e.g., 4 to only process 4-5 star images\n",
    "CAMERA_MAKE = None  # e.g., 'Canon' to filter by camera\n",
    "FILE_EXTENSIONS = None  # e.g., ['.jpg', '.jpeg'] to filter by type\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Date range: {START_DATE.date()} to {END_DATE.date()}\")\n",
    "print(f\"  YOLO model: {YOLO_MODEL} (Segmentation)\")\n",
    "print(f\"  Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"  Max images: {MAX_IMAGES or 'All'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Auto-reload enabled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Add package to path\n",
    "package_root = Path().resolve().parent\n",
    "if str(package_root) not in sys.path:\n",
    "    sys.path.insert(0, str(package_root))\n",
    "\n",
    "# Data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch (for GPU configuration)\n",
    "import torch\n",
    "\n",
    "# Database\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Home Media AI\n",
    "from home_media_ai import Media, MediaType, MediaQuery\n",
    "from home_media_ai.config import get_config\n",
    "from home_media_ai.io import read_image_as_array\n",
    "\n",
    "# YOLO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Configuration\n",
    "\n",
    "Check available GPUs and select which one to use for YOLO inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# GPU CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"GPU Information:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"âœ“ CUDA is available\")\n",
    "    print(f\"âœ“ Found {num_gpus} GPU(s)\\n\")\n",
    "    \n",
    "    # List all available GPUs\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3  # Convert to GB\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "        print(f\"  Memory: {gpu_memory:.2f} GB\")\n",
    "        print(f\"  Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "        print()\n",
    "    \n",
    "    # SET WHICH GPU TO USE HERE\n",
    "    # ==========================================\n",
    "    GPU_ID = 0  # Change this to select a different GPU (0, 1, 2, etc.)\n",
    "    # ==========================================\n",
    "    \n",
    "    # Set the GPU device\n",
    "    torch.cuda.set_device(GPU_ID)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_ID)\n",
    "    \n",
    "    selected_gpu = torch.cuda.get_device_name(GPU_ID)\n",
    "    print(f\"âœ“ Selected GPU {GPU_ID}: {selected_gpu}\")\n",
    "    print(f\"  This GPU will be used for YOLO inference\")\n",
    "    \n",
    "    # Test GPU\n",
    "    test_tensor = torch.zeros(1).cuda()\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"âœ“ GPU {current_device} is ready and accessible\")\n",
    "    \n",
    "    DEVICE = f'cuda:{GPU_ID}'\n",
    "    \n",
    "else:\n",
    "    print(\"âš  CUDA is not available\")\n",
    "    print(\"  YOLO will run on CPU (much slower)\")\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nYOLO will use device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify GPU Usage\n",
    "\n",
    "Run this cell to check actual GPU memory usage and confirm YOLO is using the correct GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory usage to verify GPU is being used\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU Memory Usage:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        # Get memory info\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**2  # MB\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**2    # MB\n",
    "        total = torch.cuda.get_device_properties(i).total_memory / 1024**2  # MB\n",
    "        \n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Allocated: {allocated:.2f} MB\")\n",
    "        print(f\"  Reserved:  {reserved:.2f} MB\")\n",
    "        print(f\"  Total:     {total:.2f} MB\")\n",
    "        \n",
    "        if i == GPU_ID:\n",
    "            print(f\"  â† This is your selected GPU\")\n",
    "        print()\n",
    "    \n",
    "    # Show which device PyTorch is currently using\n",
    "    print(f\"PyTorch current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"PyTorch device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nðŸ’¡ TIP: Watch the 'Allocated' memory - it should increase significantly\")\n",
    "    print(\"   when YOLO processes images on the GPU.\")\n",
    "else:\n",
    "    print(\"CUDA not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Troubleshooting\n",
    "\n",
    "If Task Manager shows the wrong GPU being used, here are some things to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU TROUBLESHOOTING GUIDE\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1. TASK MANAGER GPU COLUMN:\")\n",
    "print(\"   - In Task Manager, click 'Performance' tab\")\n",
    "print(\"   - Look at each GPU individually\")\n",
    "print(\"   - Check 'CUDA' or 'Compute_0' usage (not just '3D')\")\n",
    "print(\"   - Intel iGPU might show activity for display rendering only\")\n",
    "print()\n",
    "print(\"2. VERIFY WITH NVIDIA-SMI:\")\n",
    "print(\"   - Open Command Prompt or PowerShell\")\n",
    "print(\"   - Run: nvidia-smi\")\n",
    "print(\"   - Look for 'python.exe' process using GPU memory\")\n",
    "print(\"   - This is the most reliable way to check!\")\n",
    "print()\n",
    "print(\"3. GPU PROCESS ASSIGNMENT:\")\n",
    "print(\"   - Right-click on python.exe in Task Manager 'Details' tab\")\n",
    "print(\"   - Select 'Change graphics preference'\")\n",
    "print(\"   - Choose 'High performance' (forces discrete GPU)\")\n",
    "print()\n",
    "print(\"4. CHECK HYBRID GRAPHICS:\")\n",
    "print(\"   - Some laptops use 'Optimus' which routes through iGPU\")\n",
    "print(\"   - The dGPU does the compute, iGPU does the display\")\n",
    "print(\"   - This is normal and doesn't affect performance!\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Provide a command to check nvidia-smi\n",
    "print(\"\\nðŸ’¡ RUN THIS COMMAND in a separate terminal to monitor GPU:\")\n",
    "print(\"   nvidia-smi -l 1\")\n",
    "print(\"   (Updates every 1 second - watch for python.exe)\")\n",
    "print()\n",
    "print(\"   Or for a single check:\")\n",
    "print(\"   nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run nvidia-smi directly from notebook to check GPU usage\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    print(\"NVIDIA-SMI Output:\")\n",
    "    print(\"=\" * 60)\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "    print(result.stdout)\n",
    "    \n",
    "    print(\"\\nActive CUDA Processes:\")\n",
    "    print(\"=\" * 60)\n",
    "    result2 = subprocess.run(\n",
    "        ['nvidia-smi', '--query-compute-apps=pid,process_name,used_memory', '--format=csv'],\n",
    "        capture_output=True, text=True, timeout=5\n",
    "    )\n",
    "    print(result2.stdout)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âš  nvidia-smi not found in PATH\")\n",
    "    print(\"  This is normal if NVIDIA drivers aren't installed or accessible\")\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"âš  nvidia-smi command timed out\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Error running nvidia-smi: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and connect to database\n",
    "config = get_config()\n",
    "print(f\"Database URI: {config.database.uri}\")\n",
    "\n",
    "if config.database.uri:\n",
    "    engine = create_engine(config.database.uri)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    print(\"âœ“ Database connection established!\")\n",
    "else:\n",
    "    raise RuntimeError(\"No database URI configured. Set in config.yaml or HOME_MEDIA_AI_URI environment variable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Images\n",
    "\n",
    "Use MediaQuery to filter images by date range and originals only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query with filters\n",
    "query = MediaQuery(session)\n",
    "\n",
    "# Apply date range and originals filter\n",
    "query = query.date_range(START_DATE, END_DATE).originals_only()\n",
    "\n",
    "# Apply optional filters\n",
    "if MIN_RATING is not None:\n",
    "    query = query.rating_min(MIN_RATING)\n",
    "    print(f\"âœ“ Filtered to rating >= {MIN_RATING}\")\n",
    "\n",
    "if CAMERA_MAKE is not None:\n",
    "    query = query.camera_make(CAMERA_MAKE)\n",
    "    print(f\"âœ“ Filtered to camera make: {CAMERA_MAKE}\")\n",
    "\n",
    "if FILE_EXTENSIONS is not None:\n",
    "    # Apply extension filter manually since we might have multiple\n",
    "    for ext in FILE_EXTENSIONS:\n",
    "        query = query.extension(ext)\n",
    "    print(f\"âœ“ Filtered to extensions: {FILE_EXTENSIONS}\")\n",
    "\n",
    "# Sort by date for consistent processing\n",
    "query = query.sort_by_date(ascending=True)\n",
    "\n",
    "# Apply limit if specified\n",
    "if MAX_IMAGES is not None:\n",
    "    query = query.limit(MAX_IMAGES)\n",
    "    print(f\"âœ“ Limited to {MAX_IMAGES} images\")\n",
    "\n",
    "# Get results\n",
    "images = query.all()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Found {len(images)} images matching criteria\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if images:\n",
    "    print(f\"\\nFirst few results:\")\n",
    "    for i, media in enumerate(images[:5]):\n",
    "        print(f\"  {i+1}. {media.filename} - {media.created.strftime('%Y-%m-%d')}\")\n",
    "    if len(images) > 5:\n",
    "        print(f\"  ... and {len(images) - 5} more\")\n",
    "else:\n",
    "    print(\"\\nâš  No images found. Try adjusting your filters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load YOLO Model\n",
    "\n",
    "Load the YOLOv8 model for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model (will download if not already cached)\n",
    "print(f\"Loading YOLO model: {YOLO_MODEL}...\")\n",
    "model = YOLO(YOLO_MODEL)\n",
    "\n",
    "# Move model to selected device\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Get class names\n",
    "class_names = model.names\n",
    "print(f\"âœ“ Model loaded successfully!\")\n",
    "print(f\"âœ“ Model moved to device: {DEVICE}\")\n",
    "print(f\"\\nModel can detect {len(class_names)} classes:\")\n",
    "print(f\"  {', '.join(list(class_names.values())[:20])}...\")\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"  IoU threshold: {IOU_THRESHOLD}\")\n",
    "print(f\"  Input size: {RESIZE_FOR_YOLO}px\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load YOLO Model (with GPU verification)\n",
    "\n",
    "Load the YOLOv8 model and verify it's on the correct GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show GPU memory BEFORE loading model\n",
    "if torch.cuda.is_available():\n",
    "    mem_before = torch.cuda.memory_allocated(GPU_ID) / 1024**2\n",
    "    print(f\"GPU memory before loading: {mem_before:.2f} MB\\n\")\n",
    "\n",
    "# Load YOLO model (will download if not already cached)\n",
    "print(f\"Loading YOLO model: {YOLO_MODEL}...\")\n",
    "model = YOLO(YOLO_MODEL)\n",
    "\n",
    "# Move model to selected device\n",
    "print(f\"Moving model to {DEVICE}...\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Show GPU memory AFTER loading model\n",
    "if torch.cuda.is_available():\n",
    "    mem_after = torch.cuda.memory_allocated(GPU_ID) / 1024**2\n",
    "    mem_used = mem_after - mem_before\n",
    "    print(f\"\\nGPU memory after loading: {mem_after:.2f} MB\")\n",
    "    print(f\"Model uses: {mem_used:.2f} MB on GPU\")\n",
    "    \n",
    "    if mem_used < 10:\n",
    "        print(\"\\nâš  WARNING: Model memory usage is very low!\")\n",
    "        print(\"  The model might not actually be on the GPU.\")\n",
    "        print(\"  Check that DEVICE is set correctly.\")\n",
    "\n",
    "# Get class names\n",
    "class_names = model.names\n",
    "print(f\"\\nâœ“ Model loaded successfully!\")\n",
    "print(f\"âœ“ Model device: {DEVICE}\")\n",
    "print(f\"\\nModel can detect {len(class_names)} classes:\")\n",
    "print(f\"  {', '.join(list(class_names.values())[:20])}...\")\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"  IoU threshold: {IOU_THRESHOLD}\")\n",
    "print(f\"  Input size: {RESIZE_FOR_YOLO}px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Storage for all detection data\n",
    "detection_records = []\n",
    "processing_errors = []\n",
    "\n",
    "print(f\"Processing {len(images)} images through YOLO...\")\n",
    "print(f\"Using device: {DEVICE}\\n\")\n",
    "\n",
    "for idx, media in enumerate(tqdm(images, desc=\"Running YOLO\")):\n",
    "    try:\n",
    "        # Read image\n",
    "        img_array = media.read_as_array()\n",
    "        \n",
    "        # Convert to uint8 if needed\n",
    "        if img_array.dtype == np.uint16:\n",
    "            img_array = (img_array / 256).astype(np.uint8)\n",
    "        \n",
    "        # Run YOLO detection with explicit device specification\n",
    "        results = model.predict(\n",
    "            img_array,\n",
    "            conf=CONFIDENCE_THRESHOLD,\n",
    "            iou=IOU_THRESHOLD,\n",
    "            imgsz=RESIZE_FOR_YOLO,\n",
    "            device=DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Extract detection data from results\n",
    "        result = results[0]  # Single image result\n",
    "        boxes = result.boxes\n",
    "        masks = result.masks  # Segmentation masks (if available)\n",
    "        \n",
    "        # Count detections by class\n",
    "        class_counts = {}\n",
    "        confidence_scores = []\n",
    "        all_detections = []\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            for i, box in enumerate(boxes):\n",
    "                # Extract box data\n",
    "                cls_id = int(box.cls.item())\n",
    "                cls_name = class_names[cls_id]\n",
    "                confidence = float(box.conf.item())\n",
    "                bbox = box.xyxy[0].tolist()  # [x1, y1, x2, y2]\n",
    "                \n",
    "                # Track counts\n",
    "                class_counts[cls_name] = class_counts.get(cls_name, 0) + 1\n",
    "                confidence_scores.append(confidence)\n",
    "                \n",
    "                # Extract mask data if available\n",
    "                mask_data = {}\n",
    "                if masks is not None and i < len(masks):\n",
    "                    # Get mask for this detection\n",
    "                    mask = masks[i]\n",
    "                    \n",
    "                    # Mask area (number of pixels)\n",
    "                    mask_array = mask.data.cpu().numpy()[0]  # Convert to numpy\n",
    "                    mask_area = int(mask_array.sum())\n",
    "                    \n",
    "                    # Calculate mask coverage (% of bounding box covered by mask)\n",
    "                    bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "                    mask_coverage_pct = (mask_area / bbox_area * 100) if bbox_area > 0 else 0\n",
    "                    \n",
    "                    # Get polygon coordinates (simplified)\n",
    "                    if hasattr(mask, 'xy') and len(mask.xy) > 0:\n",
    "                        polygon = mask.xy[0].tolist()  # List of [x, y] coordinates\n",
    "                        # Simplify polygon if too many points (keep every Nth point)\n",
    "                        if len(polygon) > 100:\n",
    "                            step = len(polygon) // 50\n",
    "                            polygon = polygon[::step]\n",
    "                    else:\n",
    "                        polygon = None\n",
    "                    \n",
    "                    mask_data = {\n",
    "                        'has_mask': True,\n",
    "                        'mask_area': mask_area,\n",
    "                        'mask_coverage_pct': mask_coverage_pct,\n",
    "                        'mask_polygon': polygon,\n",
    "                        'mask_shape': mask_array.shape\n",
    "                    }\n",
    "                else:\n",
    "                    mask_data = {\n",
    "                        'has_mask': False,\n",
    "                        'mask_area': None,\n",
    "                        'mask_coverage_pct': None,\n",
    "                        'mask_polygon': None,\n",
    "                        'mask_shape': None\n",
    "                    }\n",
    "                \n",
    "                # Store individual detection\n",
    "                detection_dict = {\n",
    "                    'class_id': cls_id,\n",
    "                    'class_name': cls_name,\n",
    "                    'confidence': confidence,\n",
    "                    'bbox_x1': bbox[0],\n",
    "                    'bbox_y1': bbox[1],\n",
    "                    'bbox_x2': bbox[2],\n",
    "                    'bbox_y2': bbox[3],\n",
    "                    'bbox_width': bbox[2] - bbox[0],\n",
    "                    'bbox_height': bbox[3] - bbox[1],\n",
    "                    'bbox_area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]),\n",
    "                }\n",
    "                # Add mask data\n",
    "                detection_dict.update(mask_data)\n",
    "                \n",
    "                all_detections.append(detection_dict)\n",
    "        \n",
    "        # Create comprehensive record for this image\n",
    "        record = {\n",
    "            # Image metadata\n",
    "            'media_id': media.id,\n",
    "            'filename': media.filename,\n",
    "            'file_path': media.get_full_path(),\n",
    "            'file_ext': media.file_ext,\n",
    "            'file_size_mb': media.file_size / (1024 * 1024) if media.file_size else None,\n",
    "            'created': media.created,\n",
    "            'rating': media.rating,\n",
    "            \n",
    "            # Camera metadata\n",
    "            'camera_make': media.camera_make,\n",
    "            'camera_model': media.camera_model,\n",
    "            'lens_model': media.lens_model,\n",
    "            \n",
    "            # Image dimensions\n",
    "            'width': media.width,\n",
    "            'height': media.height,\n",
    "            'megapixels': (media.width * media.height) / 1_000_000 if media.width and media.height else None,\n",
    "            \n",
    "            # GPS data\n",
    "            'gps_latitude': media.gps_latitude,\n",
    "            'gps_longitude': media.gps_longitude,\n",
    "            'gps_altitude': media.gps_altitude,\n",
    "            \n",
    "            # YOLO detection summary\n",
    "            'total_detections': len(boxes),\n",
    "            'unique_classes': len(class_counts),\n",
    "            'detected_classes': ', '.join(sorted(class_counts.keys())) if class_counts else None,\n",
    "            'class_counts_json': str(class_counts) if class_counts else None,\n",
    "            \n",
    "            # Confidence statistics\n",
    "            'avg_confidence': np.mean(confidence_scores) if confidence_scores else None,\n",
    "            'min_confidence': np.min(confidence_scores) if confidence_scores else None,\n",
    "            'max_confidence': np.max(confidence_scores) if confidence_scores else None,\n",
    "            'std_confidence': np.std(confidence_scores) if confidence_scores else None,\n",
    "            \n",
    "            # Mask summary\n",
    "            'has_masks': masks is not None,\n",
    "            'total_mask_area': sum(d['mask_area'] for d in all_detections if d['has_mask']) if all_detections else 0,\n",
    "            \n",
    "            # Individual detections (as nested list of dicts)\n",
    "            'detections': all_detections,\n",
    "        }\n",
    "        \n",
    "        # Add individual class counts as separate columns\n",
    "        for cls_name, count in class_counts.items():\n",
    "            record[f'count_{cls_name}'] = count\n",
    "        \n",
    "        detection_records.append(record)\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        processing_errors.append({\n",
    "            'media_id': media.id,\n",
    "            'filename': media.filename,\n",
    "            'error': f'File not found: {str(e)}'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        processing_errors.append({\n",
    "            'media_id': media.id,\n",
    "            'filename': media.filename,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Processing complete!\")\n",
    "print(f\"  Successfully processed: {len(detection_records)} images\")\n",
    "print(f\"  Errors: {len(processing_errors)} images\")\n",
    "if detection_records and detection_records[0]['has_masks']:\n",
    "    print(f\"  âœ“ Segmentation masks extracted\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if processing_errors:\n",
    "    print(f\"\\nâš  Errors encountered:\")\n",
    "    for err in processing_errors[:5]:\n",
    "        print(f\"  - {err['filename']}: {err['error']}\")\n",
    "    if len(processing_errors) > 5:\n",
    "        print(f\"  ... and {len(processing_errors) - 5} more errors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Comprehensive DataFrame\n",
    "\n",
    "Convert detection records into a pandas DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main DataFrame (one row per image)\n",
    "df = pd.DataFrame(detection_records)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create expanded DataFrame (one row per detection)\n",
    "# This \"explodes\" the detections column so each detection gets its own row\n",
    "detection_rows = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row['detections']:  # If there are detections\n",
    "        for detection in row['detections']:\n",
    "            detection_row = {\n",
    "                # Image info\n",
    "                'media_id': row['media_id'],\n",
    "                'filename': row['filename'],\n",
    "                'created': row['created'],\n",
    "                'width': row['width'],\n",
    "                'height': row['height'],\n",
    "                \n",
    "                # Detection info\n",
    "                'class_id': detection['class_id'],\n",
    "                'class_name': detection['class_name'],\n",
    "                'confidence': detection['confidence'],\n",
    "                'bbox_x1': detection['bbox_x1'],\n",
    "                'bbox_y1': detection['bbox_y1'],\n",
    "                'bbox_x2': detection['bbox_x2'],\n",
    "                'bbox_y2': detection['bbox_y2'],\n",
    "                'bbox_width': detection['bbox_width'],\n",
    "                'bbox_height': detection['bbox_height'],\n",
    "                'bbox_area': detection['bbox_area'],\n",
    "                'bbox_area_pct': (detection['bbox_area'] / (row['width'] * row['height']) * 100) if row['width'] and row['height'] else None,\n",
    "                \n",
    "                # Mask info (if available)\n",
    "                'has_mask': detection.get('has_mask', False),\n",
    "                'mask_area': detection.get('mask_area'),\n",
    "                'mask_coverage_pct': detection.get('mask_coverage_pct'),\n",
    "            }\n",
    "            detection_rows.append(detection_row)\n",
    "\n",
    "df_detections = pd.DataFrame(detection_rows)\n",
    "\n",
    "print(f\"\\nDetections DataFrame shape: {df_detections.shape}\")\n",
    "print(f\"Total individual detections: {len(df_detections)}\")\n",
    "\n",
    "if 'has_mask' in df_detections.columns:\n",
    "    masks_count = df_detections['has_mask'].sum()\n",
    "    print(f\"Detections with masks: {masks_count}\")\n",
    "    if masks_count > 0:\n",
    "        print(f\"\\nMask Statistics:\")\n",
    "        print(f\"  Average mask area: {df_detections[df_detections['has_mask']]['mask_area'].mean():.0f} pixels\")\n",
    "        print(f\"  Average mask coverage: {df_detections[df_detections['has_mask']]['mask_coverage_pct'].mean():.1f}% of bbox\")\n",
    "\n",
    "print(f\"\\nFirst few detection rows:\")\n",
    "df_detections.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"YOLO DETECTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nImages Processed: {len(df)}\")\n",
    "print(f\"Total Detections: {df['total_detections'].sum():.0f}\")\n",
    "print(f\"Images with Detections: {(df['total_detections'] > 0).sum()}\")\n",
    "print(f\"Images with No Detections: {(df['total_detections'] == 0).sum()}\")\n",
    "\n",
    "print(f\"\\nDetections per Image:\")\n",
    "print(f\"  Mean: {df['total_detections'].mean():.2f}\")\n",
    "print(f\"  Median: {df['total_detections'].median():.0f}\")\n",
    "print(f\"  Max: {df['total_detections'].max():.0f}\")\n",
    "print(f\"  Std Dev: {df['total_detections'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nConfidence Scores:\")\n",
    "print(f\"  Mean: {df['avg_confidence'].mean():.3f}\")\n",
    "print(f\"  Min: {df['min_confidence'].min():.3f}\")\n",
    "print(f\"  Max: {df['max_confidence'].max():.3f}\")\n",
    "\n",
    "# Top detected classes\n",
    "if len(df_detections) > 0:\n",
    "    print(f\"\\nTop 20 Detected Classes:\")\n",
    "    class_counts = df_detections['class_name'].value_counts()\n",
    "    for i, (cls, count) in enumerate(class_counts.head(20).items(), 1):\n",
    "        pct = (count / len(df_detections)) * 100\n",
    "        print(f\"  {i:2d}. {cls:20s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Detection Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Histogram of detections per image\n",
    "axes[0, 0].hist(df['total_detections'], bins=30, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Number of Detections')\n",
    "axes[0, 0].set_ylabel('Number of Images')\n",
    "axes[0, 0].set_title('Distribution of Detections per Image')\n",
    "axes[0, 0].axvline(df['total_detections'].mean(), color='red', linestyle='--', label=f\"Mean: {df['total_detections'].mean():.1f}\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Top 15 classes by count\n",
    "if len(df_detections) > 0:\n",
    "    top_classes = df_detections['class_name'].value_counts().head(15)\n",
    "    axes[0, 1].barh(range(len(top_classes)), top_classes.values)\n",
    "    axes[0, 1].set_yticks(range(len(top_classes)))\n",
    "    axes[0, 1].set_yticklabels(top_classes.index)\n",
    "    axes[0, 1].set_xlabel('Count')\n",
    "    axes[0, 1].set_title('Top 15 Detected Classes')\n",
    "    axes[0, 1].invert_yaxis()\n",
    "\n",
    "# 3. Confidence score distribution\n",
    "if len(df_detections) > 0:\n",
    "    axes[1, 0].hist(df_detections['confidence'], bins=30, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Confidence Score')\n",
    "    axes[1, 0].set_ylabel('Number of Detections')\n",
    "    axes[1, 0].set_title('Distribution of Confidence Scores')\n",
    "    axes[1, 0].axvline(df_detections['confidence'].mean(), color='red', linestyle='--', label=f\"Mean: {df_detections['confidence'].mean():.2f}\")\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 4. Detections over time\n",
    "if 'created' in df.columns:\n",
    "    df_sorted = df.sort_values('created')\n",
    "    axes[1, 1].plot(df_sorted['created'], df_sorted['total_detections'], alpha=0.5, marker='o', markersize=3, linestyle='-')\n",
    "    axes[1, 1].set_xlabel('Date')\n",
    "    axes[1, 1].set_ylabel('Total Detections')\n",
    "    axes[1, 1].set_title('Detections Over Time')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Detections with Bounding Boxes\n",
    "\n",
    "Display random sample images with their YOLO detections overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_detections(media, detections_list, ax=None):\n",
    "    \"\"\"\n",
    "    Plot an image with YOLO detections overlaid.\n",
    "    \n",
    "    Args:\n",
    "        media: Media object\n",
    "        detections_list: List of detection dictionaries\n",
    "        ax: Matplotlib axis (optional)\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Read and display image\n",
    "    img_array = media.read_as_array()\n",
    "    if img_array.dtype == np.uint16:\n",
    "        img_array = (img_array / 256).astype(np.uint8)\n",
    "    \n",
    "    ax.imshow(img_array)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "    \n",
    "    for i, det in enumerate(detections_list):\n",
    "        x1, y1 = det['bbox_x1'], det['bbox_y1']\n",
    "        width = det['bbox_width']\n",
    "        height = det['bbox_height']\n",
    "        \n",
    "        # Choose color based on class\n",
    "        color = colors[det['class_id'] % len(colors)]\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label = f\"{det['class_name']} {det['confidence']:.2f}\"\n",
    "        ax.text(\n",
    "            x1, y1 - 5,\n",
    "            label,\n",
    "            color='white',\n",
    "            fontsize=10,\n",
    "            bbox=dict(facecolor=color, alpha=0.8, edgecolor='none', pad=2)\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"{media.filename}\\n{len(detections_list)} detections\", fontsize=10)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "# Select random sample with detections\n",
    "NUM_SAMPLES = 6\n",
    "df_with_detections = df[df['total_detections'] > 0]\n",
    "\n",
    "if len(df_with_detections) > 0:\n",
    "    sample_df = df_with_detections.sample(min(NUM_SAMPLES, len(df_with_detections)))\n",
    "    \n",
    "    # Create grid\n",
    "    n_cols = 3\n",
    "    n_rows = (len(sample_df) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        ax_row = idx // n_cols\n",
    "        ax_col = idx % n_cols\n",
    "        \n",
    "        # Get media object\n",
    "        media = session.query(Media).filter(Media.id == row['media_id']).first()\n",
    "        \n",
    "        if media:\n",
    "            try:\n",
    "                plot_image_with_detections(media, row['detections'], axes[ax_row, ax_col])\n",
    "            except Exception as e:\n",
    "                axes[ax_row, ax_col].text(0.5, 0.5, f\"Error: {str(e)}\", ha='center', va='center')\n",
    "                axes[ax_row, ax_col].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(sample_df), n_rows * n_cols):\n",
    "        ax_row = idx // n_cols\n",
    "        ax_col = idx % n_cols\n",
    "        axes[ax_row, ax_col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images with detections to display.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Masks Only vs. Masks + Bounding Boxes\n",
    "\n",
    "Compare the segmentation masks with and without bounding boxes to see the precision of pixel-level detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_masks(media, detections_list, ax=None, show_boxes=True, mask_alpha=0.4):\n",
    "    \"\"\"\n",
    "    Plot an image with segmentation masks overlaid.\n",
    "    \n",
    "    Args:\n",
    "        media: Media object\n",
    "        detections_list: List of detection dictionaries (must include mask_polygon)\n",
    "        ax: Matplotlib axis (optional)\n",
    "        show_boxes: If True, also draw bounding boxes\n",
    "        mask_alpha: Transparency of mask overlay (0-1)\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Read and display image\n",
    "    img_array = media.read_as_array()\n",
    "    if img_array.dtype == np.uint16:\n",
    "        img_array = (img_array / 256).astype(np.uint8)\n",
    "    \n",
    "    ax.imshow(img_array)\n",
    "    \n",
    "    # Create color map\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "    \n",
    "    # Draw masks and boxes\n",
    "    for i, det in enumerate(detections_list):\n",
    "        # Choose color based on class\n",
    "        color = colors[det['class_id'] % len(colors)]\n",
    "        \n",
    "        # Draw segmentation mask if available\n",
    "        if det.get('has_mask') and det.get('mask_polygon') is not None:\n",
    "            polygon = np.array(det['mask_polygon'])\n",
    "            \n",
    "            # Draw filled polygon with transparency\n",
    "            mask_patch = patches.Polygon(\n",
    "                polygon,\n",
    "                closed=True,\n",
    "                facecolor=color,\n",
    "                edgecolor=color,\n",
    "                alpha=mask_alpha,\n",
    "                linewidth=2\n",
    "            )\n",
    "            ax.add_patch(mask_patch)\n",
    "            \n",
    "            # Draw mask contour (outline)\n",
    "            contour = patches.Polygon(\n",
    "                polygon,\n",
    "                closed=True,\n",
    "                facecolor='none',\n",
    "                edgecolor=color,\n",
    "                alpha=1.0,\n",
    "                linewidth=2\n",
    "            )\n",
    "            ax.add_patch(contour)\n",
    "        \n",
    "        # Optionally draw bounding box\n",
    "        if show_boxes:\n",
    "            x1, y1 = det['bbox_x1'], det['bbox_y1']\n",
    "            width = det['bbox_width']\n",
    "            height = det['bbox_height']\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), width, height,\n",
    "                linewidth=1, edgecolor=color, facecolor='none',\n",
    "                linestyle='--', alpha=0.5\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        # Add label at top of detection\n",
    "        x1, y1 = det['bbox_x1'], det['bbox_y1']\n",
    "        label = f\"{det['class_name']} {det['confidence']:.2f}\"\n",
    "        if det.get('has_mask'):\n",
    "            label += f\" ({det.get('mask_coverage_pct', 0):.0f}%)\"\n",
    "        \n",
    "        ax.text(\n",
    "            x1, y1 - 5,\n",
    "            label,\n",
    "            color='white',\n",
    "            fontsize=9,\n",
    "            bbox=dict(facecolor=color, alpha=0.8, edgecolor='none', pad=2)\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    title = f\"{media.filename}\\n{len(detections_list)} detections\"\n",
    "    if detections_list and detections_list[0].get('has_mask'):\n",
    "        masks_count = sum(1 for d in detections_list if d.get('has_mask'))\n",
    "        title += f\", {masks_count} with masks\"\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "# Select random sample with detections that have masks\n",
    "NUM_SAMPLES = 6\n",
    "df_with_masks = df[(df['total_detections'] > 0) & (df['has_masks'] == True)]\n",
    "\n",
    "if len(df_with_masks) > 0:\n",
    "    sample_df = df_with_masks.sample(min(NUM_SAMPLES, len(df_with_masks)))\n",
    "    \n",
    "    # Create grid\n",
    "    n_cols = 3\n",
    "    n_rows = (len(sample_df) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        ax_row = idx // n_cols\n",
    "        ax_col = idx % n_cols\n",
    "        \n",
    "        # Get media object\n",
    "        media = session.query(Media).filter(Media.id == row['media_id']).first()\n",
    "        \n",
    "        if media:\n",
    "            try:\n",
    "                plot_image_with_masks(\n",
    "                    media, \n",
    "                    row['detections'], \n",
    "                    axes[ax_row, ax_col],\n",
    "                    show_boxes=True,  # Show both masks and boxes\n",
    "                    mask_alpha=0.35\n",
    "                )\n",
    "            except Exception as e:\n",
    "                axes[ax_row, ax_col].text(0.5, 0.5, f\"Error: {str(e)}\", ha='center', va='center')\n",
    "                axes[ax_row, ax_col].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(sample_df), n_rows * n_cols):\n",
    "        ax_row = idx // n_cols\n",
    "        ax_col = idx % n_cols\n",
    "        axes[ax_row, ax_col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ’¡ Legend:\")\n",
    "    print(\"  - Colored filled areas: Segmentation masks (pixel-level object boundaries)\")\n",
    "    print(\"  - Dashed boxes: Bounding boxes (for reference)\")\n",
    "    print(\"  - Percentage in label: How much of the bounding box is covered by the mask\")\n",
    "else:\n",
    "    print(\"No images with segmentation masks to display.\")\n",
    "    print(\"Make sure you're using a segmentation model (yolov8n-seg.pt)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side comparison: Masks Only vs Masks + Boxes\n",
    "NUM_COMPARISON = 3\n",
    "\n",
    "if len(df_with_masks) > 0:\n",
    "    # Select images for comparison\n",
    "    comparison_df = df_with_masks.sample(min(NUM_COMPARISON, len(df_with_masks)))\n",
    "    \n",
    "    # Create grid: 2 columns (masks only, masks+boxes) x N rows\n",
    "    fig, axes = plt.subplots(len(comparison_df), 2, figsize=(16, 6 * len(comparison_df)))\n",
    "    \n",
    "    # Handle single row case\n",
    "    if len(comparison_df) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "        # Get media object\n",
    "        media = session.query(Media).filter(Media.id == row['media_id']).first()\n",
    "        \n",
    "        if media:\n",
    "            try:\n",
    "                # Left: Masks only\n",
    "                plot_image_with_masks(\n",
    "                    media, \n",
    "                    row['detections'], \n",
    "                    axes[idx, 0],\n",
    "                    show_boxes=False,  # No bounding boxes\n",
    "                    mask_alpha=0.45\n",
    "                )\n",
    "                axes[idx, 0].set_title(f\"{media.filename}\\nSegmentation Masks Only\", fontsize=10)\n",
    "                \n",
    "                # Right: Masks + Boxes\n",
    "                plot_image_with_masks(\n",
    "                    media, \n",
    "                    row['detections'], \n",
    "                    axes[idx, 1],\n",
    "                    show_boxes=True,  # With bounding boxes\n",
    "                    mask_alpha=0.35\n",
    "                )\n",
    "                axes[idx, 1].set_title(f\"{media.filename}\\nMasks + Bounding Boxes\", fontsize=10)\n",
    "                \n",
    "            except Exception as e:\n",
    "                for col in [0, 1]:\n",
    "                    axes[idx, col].text(0.5, 0.5, f\"Error: {str(e)}\", ha='center', va='center')\n",
    "                    axes[idx, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“Š Comparison Notes:\")\n",
    "    print(\"  - Left: Shows only the segmentation masks (pixel-precise object shapes)\")\n",
    "    print(\"  - Right: Shows both masks and bounding boxes (dashed lines)\")\n",
    "    print(\"  - Notice how masks follow the actual object contours, not just rectangles\")\n",
    "else:\n",
    "    print(\"No images with segmentation masks available for comparison.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Segmentation Masks\n",
    "\n",
    "Display sample images with pixel-level segmentation masks overlaid. The masks show the exact shape of detected objects, not just bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis: Detection Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which classes tend to appear together\n",
    "if len(df_detections) > 0:\n",
    "    print(\"CLASS CO-OCCURRENCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get top 10 classes\n",
    "    top_10_classes = df_detections['class_name'].value_counts().head(10).index.tolist()\n",
    "    \n",
    "    # Build co-occurrence matrix (integers while counting)\n",
    "    cooccurrence = pd.DataFrame(0, index=top_10_classes, columns=top_10_classes)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['detections']:\n",
    "            classes_in_image = [d['class_name'] for d in row['detections'] if d['class_name'] in top_10_classes]\n",
    "            # Count co-occurrences\n",
    "            for i, cls1 in enumerate(classes_in_image):\n",
    "                for cls2 in classes_in_image[i:]:\n",
    "                    cooccurrence.loc[cls1, cls2] += 1\n",
    "                    if cls1 != cls2:\n",
    "                        cooccurrence.loc[cls2, cls1] += 1\n",
    "    \n",
    "    # Zero out diagonal (class co-occurring with itself)\n",
    "    np.fill_diagonal(cooccurrence.values, 0)\n",
    "    \n",
    "    # Create mask for upper triangular part (including diagonal)\n",
    "    mask = np.triu(np.ones_like(cooccurrence, dtype=bool))\n",
    "    \n",
    "    # Create a masked (float) version for visualization so NaN assignment is allowed\n",
    "    cooccurrence_upper = cooccurrence.astype(float).copy()\n",
    "    cooccurrence_upper.values[~mask] = np.nan  # Set lower triangle to NaN\n",
    "    \n",
    "    # Visualize co-occurrence matrix (upper triangle only)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Use masked array to hide lower triangle\n",
    "    im = plt.imshow(cooccurrence_upper.values, cmap='YlOrRd', aspect='auto')\n",
    "    plt.colorbar(im, label='Co-occurrence Count')\n",
    "    plt.xticks(range(len(top_10_classes)), top_10_classes, rotation=45, ha='right')\n",
    "    plt.yticks(range(len(top_10_classes)), top_10_classes)\n",
    "    plt.title('Class Co-occurrence Matrix (Top 10 Classes)\\nUpper Triangle Only - Diagonal Zeroed')\n",
    "    \n",
    "    # Add text annotations only for upper triangle\n",
    "    for i in range(len(top_10_classes)):\n",
    "        for j in range(len(top_10_classes)):\n",
    "            if mask[i, j]:  # Only annotate upper triangle\n",
    "                value = cooccurrence.iloc[i, j]  # Original integer counts\n",
    "                # Use pandas isna check to safely handle types\n",
    "                if pd.notna(value) and value > 0:  # Check for valid, non-zero values\n",
    "                    plt.text(j, i, int(value),\n",
    "                             ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nMost Common Class Pairs:\")\n",
    "    pairs = []\n",
    "    for i, cls1 in enumerate(top_10_classes):\n",
    "        for j, cls2 in enumerate(top_10_classes[i+1:], i+1):\n",
    "            count = cooccurrence.loc[cls1, cls2]\n",
    "            if count > 0:\n",
    "                pairs.append((cls1, cls2, int(count)))\n",
    "    \n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    for i, (cls1, cls2, count) in enumerate(pairs[:15], 1):\n",
    "        print(f\"  {i:2d}. {cls1:15s} + {cls2:15s}: {count:3d} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export DataFrames for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Export to CSV for external analysis\n",
    "EXPORT_CSV = False  # Set to True to export\n",
    "\n",
    "if EXPORT_CSV:\n",
    "    output_dir = Path('../output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export main DataFrame (without nested detections)\n",
    "    df_export = df.drop(columns=['detections'])\n",
    "    df_export.to_csv(output_dir / 'yolo_analysis_images.csv', index=False)\n",
    "    print(f\"âœ“ Exported image-level data to: {output_dir / 'yolo_analysis_images.csv'}\")\n",
    "    \n",
    "    # Export detections DataFrame\n",
    "    df_detections.to_csv(output_dir / 'yolo_analysis_detections.csv', index=False)\n",
    "    print(f\"âœ“ Exported detection-level data to: {output_dir / 'yolo_analysis_detections.csv'}\")\n",
    "else:\n",
    "    print(\"CSV export disabled. Set EXPORT_CSV = True to enable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: DataFrames Available\n",
    "\n",
    "After running this notebook, you have access to:\n",
    "\n",
    "1. **`df`** - Main DataFrame with one row per image\n",
    "   - All image metadata (filename, date, camera, GPS, etc.)\n",
    "   - YOLO detection summaries (total detections, classes, confidence stats)\n",
    "   - Nested `detections` column with full detection data\n",
    "\n",
    "2. **`df_detections`** - Expanded DataFrame with one row per detection\n",
    "   - Individual detection details (class, confidence, bounding box)\n",
    "   - Linked to source image via `media_id`\n",
    "\n",
    "Use these DataFrames to experiment with features you want to add to the database!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "if session:\n",
    "    session.close()\n",
    "    print(\"Database session closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
