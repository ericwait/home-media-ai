{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox Notebook\n",
    "\n",
    "Experimental notebook for testing `home_media` package functionality.\n",
    "\n",
    "Auto-reload is enabled to pick up changes to the package without restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Enable auto-reload for the home_media package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Add parent directory to path so we can import home_media\n",
    "sys.path.insert(0, str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "photos_root_original: \\\\tiger\\photo\\RAW\n"
     ]
    }
   ],
   "source": [
    "# Load config from config.yaml\n",
    "config_path = Path.cwd().parent / \"config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"photos_root_original: {config['photos_root_original']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Subdirectories in photos_root_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing subdirectories in: \\\\tiger\\photo\\RAW\n",
      "\n",
      "Found 29 subdirectories:\n",
      "\n",
      "  üìÅ 1979\n",
      "  üìÅ 1988\n",
      "  üìÅ 2000\n",
      "  üìÅ 2003\n",
      "  üìÅ 2004\n",
      "  üìÅ 2005\n",
      "  üìÅ 2006\n",
      "  üìÅ 2007\n",
      "  üìÅ 2008\n",
      "  üìÅ 2009\n",
      "  üìÅ 2010\n",
      "  üìÅ 2011\n",
      "  üìÅ 2012\n",
      "  üìÅ 2013\n",
      "  üìÅ 2014\n",
      "  üìÅ 2015\n",
      "  üìÅ 2016\n",
      "  üìÅ 2017\n",
      "  üìÅ 2018\n",
      "  üìÅ 2019\n",
      "  üìÅ 2020\n",
      "  üìÅ 2021\n",
      "  üìÅ 2022\n",
      "  üìÅ 2023\n",
      "  üìÅ 2024\n",
      "  üìÅ 2025\n",
      "  üìÅ advantix\n",
      "  üìÅ advantix copy\n",
      "  üìÅ scanned\n"
     ]
    }
   ],
   "source": [
    "# Get the photos root directory\n",
    "photos_root = Path(config['photos_root_original'])\n",
    "\n",
    "print(f\"Listing subdirectories in: {photos_root}\\n\")\n",
    "\n",
    "# Check if path exists\n",
    "if not photos_root.exists():\n",
    "    print(f\"ERROR: Path does not exist: {photos_root}\")\n",
    "elif not photos_root.is_dir():\n",
    "    print(f\"ERROR: Path is not a directory: {photos_root}\")\n",
    "else:\n",
    "    # List all subdirectories\n",
    "    subdirs = [d for d in photos_root.iterdir() if d.is_dir()]\n",
    "    \n",
    "    print(f\"Found {len(subdirs)} subdirectories:\\n\")\n",
    "    \n",
    "    for subdir in sorted(subdirs):\n",
    "        print(f\"  üìÅ {subdir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining directory: \\\\tiger\\photo\\RAW\\2025\\01\\01\n",
      "Subdirectory (relative): 2025/01/01\n",
      "Number of files: 220\n",
      "\n",
      "First 5 files:\n",
      "  üìÑ 2025-01-01_00-28-40.jpg\n",
      "  üìÑ 2025-01-01_00-28-40.jpg.xmp\n",
      "  üìÑ 2025-01-01_00-28-40_001.jpg\n",
      "  üìÑ 2025-01-01_00-28-40_001.jpg.xmp\n",
      "  üìÑ 2025-01-01_00-28-40_01.jpg.xmp\n",
      "\n",
      "Created DataFrame with 220 files\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>extension</th>\n",
       "      <th>subdirectory</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01_00-28-40.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-01-01 00:29:28.492810</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1884153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01_00-28-40.jpg.xmp</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.438514</td>\n",
       "      <td>2025-09-05 07:04:46.686699</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01_00-28-40_001.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-05-02 12:09:18.121342</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1884153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01_00-28-40_001.jpg.xmp</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.495514</td>\n",
       "      <td>2025-09-05 07:04:46.827275</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01_00-28-40_01.jpg.xmp</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-05 07:04:46.434260</td>\n",
       "      <td>2025-09-05 07:04:46.436888</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-01_00-28-55.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-01-01 00:29:28.365809</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1099626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-01_00-28-55.jpg.xmp</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.566514</td>\n",
       "      <td>2025-09-05 07:04:46.928044</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-01_00-28-55_001.jpg</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-05-02 12:09:15.869327</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1099626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-01_00-28-55_001.jpg.xmp</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.615515</td>\n",
       "      <td>2025-09-05 07:04:46.939296</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-01_00-28-55_01.jpg.xmp</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-05 07:04:46.870264</td>\n",
       "      <td>2025-09-05 07:04:46.872339</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename extension subdirectory  \\\n",
       "0          2025-01-01_00-28-40.jpg      .jpg   2025\\01\\01   \n",
       "1      2025-01-01_00-28-40.jpg.xmp      .xmp   2025\\01\\01   \n",
       "2      2025-01-01_00-28-40_001.jpg      .jpg   2025\\01\\01   \n",
       "3  2025-01-01_00-28-40_001.jpg.xmp      .xmp   2025\\01\\01   \n",
       "4   2025-01-01_00-28-40_01.jpg.xmp      .xmp   2025\\01\\01   \n",
       "5          2025-01-01_00-28-55.jpg      .jpg   2025\\01\\01   \n",
       "6      2025-01-01_00-28-55.jpg.xmp      .xmp   2025\\01\\01   \n",
       "7      2025-01-01_00-28-55_001.jpg      .jpg   2025\\01\\01   \n",
       "8  2025-01-01_00-28-55_001.jpg.xmp      .xmp   2025\\01\\01   \n",
       "9   2025-01-01_00-28-55_01.jpg.xmp      .xmp   2025\\01\\01   \n",
       "\n",
       "                     created                   modified  size_bytes  \n",
       "0 2025-01-01 00:29:28.492810 2025-01-01 00:29:24.000000     1884153  \n",
       "1 2025-09-04 14:52:42.438514 2025-09-05 07:04:46.686699        1383  \n",
       "2 2025-05-02 12:09:18.121342 2025-01-01 00:29:24.000000     1884153  \n",
       "3 2025-09-04 14:52:42.495514 2025-09-05 07:04:46.827275        1387  \n",
       "4 2025-09-05 07:04:46.434260 2025-09-05 07:04:46.436888        1383  \n",
       "5 2025-01-01 00:29:28.365809 2025-01-01 00:29:24.000000     1099626  \n",
       "6 2025-09-04 14:52:42.566514 2025-09-05 07:04:46.928044        1383  \n",
       "7 2025-05-02 12:09:15.869327 2025-01-01 00:29:24.000000     1099626  \n",
       "8 2025-09-04 14:52:42.615515 2025-09-05 07:04:46.939296        1387  \n",
       "9 2025-09-05 07:04:46.870264 2025-09-05 07:04:46.872339        1383  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at files in a specific subdirectory\n",
    "subdir = \"2025/01/01\"\n",
    "target_dir = photos_root / subdir\n",
    "\n",
    "print(f\"Examining directory: {target_dir}\")\n",
    "print(f\"Subdirectory (relative): {subdir}\")\n",
    "\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    file_list = [f for f in target_dir.iterdir() if f.is_file()]\n",
    "    print(f\"Number of files: {len(file_list)}\")\n",
    "    \n",
    "    # Show first 5 files as examples\n",
    "    print(f\"\\nFirst 5 files:\")\n",
    "    for f in file_list[:5]:\n",
    "        print(f\"  üìÑ {f.name}\")\n",
    "else:\n",
    "    print(f\"ERROR: Directory does not exist or is not accessible\")\n",
    "\n",
    "# Create a list to hold file metadata\n",
    "file_data = []\n",
    "\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    for file_path in target_dir.iterdir():\n",
    "        if file_path.is_file():\n",
    "            # Get file stats\n",
    "            stats = file_path.stat()\n",
    "            \n",
    "            # Get relative subdirectory path from photos_root_original\n",
    "            rel_subdir = file_path.parent.relative_to(photos_root)\n",
    "            \n",
    "            file_data.append({\n",
    "                'filename': file_path.name,\n",
    "                'extension': file_path.suffix.lower(),\n",
    "                'subdirectory': str(rel_subdir),\n",
    "                'created': datetime.datetime.fromtimestamp(stats.st_ctime),\n",
    "                'modified': datetime.datetime.fromtimestamp(stats.st_mtime),\n",
    "                'size_bytes': stats.st_size\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(file_data)\n",
    "\n",
    "print(f\"\\nCreated DataFrame with {len(df)} files\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Filename Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique base names: 182\n",
      "\n",
      "Examples of files with same base name:\n",
      "\n",
      "2025-01-01_10-22-31:\n",
      "  - 2025-01-01_10-22-31.dng\n",
      "  - 2025-01-01_10-22-31.jpg\n",
      "\n",
      "2025-01-01_10-22-33:\n",
      "  - 2025-01-01_10-22-33.dng\n",
      "  - 2025-01-01_10-22-33.jpg\n",
      "\n",
      "2025-01-01_11-01-07:\n",
      "  - 2025-01-01_11-01-07.dng\n",
      "  - 2025-01-01_11-01-07.jpg\n",
      "\n",
      "2025-01-01_11-01-10:\n",
      "  - 2025-01-01_11-01-10.dng\n",
      "  - 2025-01-01_11-01-10.jpg\n",
      "\n",
      "2025-01-01_11-01-12:\n",
      "  - 2025-01-01_11-01-12.dng\n",
      "  - 2025-01-01_11-01-12.jpg\n",
      "\n",
      "\n",
      "Base names with multiple files: 38\n",
      "Base names with single file: 144\n"
     ]
    }
   ],
   "source": [
    "# Analyze filename patterns to find common prefixes\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group files by their base name (without extension)\n",
    "file_groups = defaultdict(list)\n",
    "\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    for file_path in target_dir.iterdir():\n",
    "        if file_path.is_file():\n",
    "            # Get the stem (filename without extension)\n",
    "            base_name = file_path.stem\n",
    "            file_groups[base_name].append(file_path)\n",
    "\n",
    "# Show some examples of grouped files\n",
    "print(f\"Total unique base names: {len(file_groups)}\\n\")\n",
    "print(\"Examples of files with same base name:\\n\")\n",
    "\n",
    "count = 0\n",
    "for base_name, files in sorted(file_groups.items()):\n",
    "    if len(files) > 1:  # Only show groups with multiple files\n",
    "        print(f\"{base_name}:\")\n",
    "        for f in files:\n",
    "            print(f\"  - {f.name}\")\n",
    "        print()\n",
    "        count += 1\n",
    "        if count >= 5:  # Show first 5 examples\n",
    "            break\n",
    "\n",
    "# Count how many base names have multiple files\n",
    "multi_file_groups = {k: v for k, v in file_groups.items() if len(v) > 1}\n",
    "print(f\"\\nBase names with multiple files: {len(multi_file_groups)}\")\n",
    "print(f\"Base names with single file: {len(file_groups) - len(multi_file_groups)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Grouped DataFrame (One Row Per Base Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grouped DataFrame with 182 unique base names\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_name</th>\n",
       "      <th>file_count</th>\n",
       "      <th>extensions</th>\n",
       "      <th>subdirectory</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>total_size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01_00-28-40</td>\n",
       "      <td>1</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-01-01 00:29:28.492810</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1884153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01_00-28-40.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.438514</td>\n",
       "      <td>2025-09-05 07:04:46.686699</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01_00-28-40_001</td>\n",
       "      <td>1</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-05-02 12:09:18.121342</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1884153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01_00-28-40_001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.495514</td>\n",
       "      <td>2025-09-05 07:04:46.827275</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01_00-28-40_01.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-05 07:04:46.434260</td>\n",
       "      <td>2025-09-05 07:04:46.436888</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-01_00-28-55</td>\n",
       "      <td>1</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-01-01 00:29:28.365809</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1099626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-01_00-28-55.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.566514</td>\n",
       "      <td>2025-09-05 07:04:46.928044</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-01_00-28-55_001</td>\n",
       "      <td>1</td>\n",
       "      <td>.jpg</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-05-02 12:09:15.869327</td>\n",
       "      <td>2025-01-01 00:29:24.000000</td>\n",
       "      <td>1099626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-01_00-28-55_001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-04 14:52:42.615515</td>\n",
       "      <td>2025-09-05 07:04:46.939296</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-01_00-28-55_01.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>.xmp</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "      <td>2025-09-05 07:04:46.870264</td>\n",
       "      <td>2025-09-05 07:04:46.872339</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     base_name  file_count extensions subdirectory  \\\n",
       "0          2025-01-01_00-28-40           1       .jpg   2025\\01\\01   \n",
       "1      2025-01-01_00-28-40.jpg           1       .xmp   2025\\01\\01   \n",
       "2      2025-01-01_00-28-40_001           1       .jpg   2025\\01\\01   \n",
       "3  2025-01-01_00-28-40_001.jpg           1       .xmp   2025\\01\\01   \n",
       "4   2025-01-01_00-28-40_01.jpg           1       .xmp   2025\\01\\01   \n",
       "5          2025-01-01_00-28-55           1       .jpg   2025\\01\\01   \n",
       "6      2025-01-01_00-28-55.jpg           1       .xmp   2025\\01\\01   \n",
       "7      2025-01-01_00-28-55_001           1       .jpg   2025\\01\\01   \n",
       "8  2025-01-01_00-28-55_001.jpg           1       .xmp   2025\\01\\01   \n",
       "9   2025-01-01_00-28-55_01.jpg           1       .xmp   2025\\01\\01   \n",
       "\n",
       "                     created                   modified  total_size_bytes  \n",
       "0 2025-01-01 00:29:28.492810 2025-01-01 00:29:24.000000           1884153  \n",
       "1 2025-09-04 14:52:42.438514 2025-09-05 07:04:46.686699              1383  \n",
       "2 2025-05-02 12:09:18.121342 2025-01-01 00:29:24.000000           1884153  \n",
       "3 2025-09-04 14:52:42.495514 2025-09-05 07:04:46.827275              1387  \n",
       "4 2025-09-05 07:04:46.434260 2025-09-05 07:04:46.436888              1383  \n",
       "5 2025-01-01 00:29:28.365809 2025-01-01 00:29:24.000000           1099626  \n",
       "6 2025-09-04 14:52:42.566514 2025-09-05 07:04:46.928044              1383  \n",
       "7 2025-05-02 12:09:15.869327 2025-01-01 00:29:24.000000           1099626  \n",
       "8 2025-09-04 14:52:42.615515 2025-09-05 07:04:46.939296              1387  \n",
       "9 2025-09-05 07:04:46.870264 2025-09-05 07:04:46.872339              1383  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with one row per base name (grouped files)\n",
    "grouped_data = []\n",
    "\n",
    "for base_name, files in sorted(file_groups.items()):\n",
    "    # Get all extensions for this base name\n",
    "    extensions = [f.suffix.lower() for f in files]\n",
    "    \n",
    "    # Get the earliest created and latest modified dates across all variants\n",
    "    created_dates = [datetime.datetime.fromtimestamp(f.stat().st_ctime) for f in files]\n",
    "    modified_dates = [datetime.datetime.fromtimestamp(f.stat().st_mtime) for f in files]\n",
    "    \n",
    "    # Get total size of all variants\n",
    "    total_size = sum(f.stat().st_size for f in files)\n",
    "    \n",
    "    # Get relative subdirectory (same for all files in group)\n",
    "    rel_subdir = files[0].parent.relative_to(photos_root)\n",
    "    \n",
    "    grouped_data.append({\n",
    "        'base_name': base_name,\n",
    "        'file_count': len(files),\n",
    "        'extensions': ', '.join(sorted(extensions)),\n",
    "        'subdirectory': str(rel_subdir),\n",
    "        'created': min(created_dates),\n",
    "        'modified': max(modified_dates),\n",
    "        'total_size_bytes': total_size\n",
    "    })\n",
    "\n",
    "# Create grouped DataFrame\n",
    "df_grouped = pd.DataFrame(grouped_data)\n",
    "\n",
    "print(f\"Created grouped DataFrame with {len(df_grouped)} unique base names\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df_grouped.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Row Per Image with Suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created image DataFrame with 49 unique images\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_name</th>\n",
       "      <th>suffixes</th>\n",
       "      <th>file_count</th>\n",
       "      <th>subdirectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01_00-28-40</td>\n",
       "      <td>[.jpg.xmp, _01.jpg.xmp, _001.jpg, _001.jpg.xmp...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01_00-28-55</td>\n",
       "      <td>[.jpg.xmp, .jpg, _001.jpg, _001.jpg.xmp, _01.j...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01_00-28-57</td>\n",
       "      <td>[_01.jpg.xmp, .jpg, _001.jpg.xmp, .jpg.xmp, _0...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01_10-22-31</td>\n",
       "      <td>[.dng.xmp, .jpg, .dng, .jpg.xmp]</td>\n",
       "      <td>4</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01_10-22-33</td>\n",
       "      <td>[.jpg, .dng.xmp, .jpg.xmp, .dng]</td>\n",
       "      <td>4</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-01_11-01-07</td>\n",
       "      <td>[.dng, .jpg, .jpg.xmp, .dng.xmp]</td>\n",
       "      <td>4</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-01_11-01-10</td>\n",
       "      <td>[.jpg.xmp, .dng, .dng.xmp, .jpg]</td>\n",
       "      <td>4</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-01_11-01-12</td>\n",
       "      <td>[.dng, .jpg.xmp, .jpg, .dng.xmp]</td>\n",
       "      <td>4</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-01_11-01-13</td>\n",
       "      <td>[.dng.xmp, .jpg.xmp, .dng, .jpg]</td>\n",
       "      <td>4</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-01_11-06-48</td>\n",
       "      <td>[.jpg, _01.jpg.xmp, _001.jpg.xmp, _001.jpg, .j...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025\\01\\01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             base_name                                           suffixes  \\\n",
       "0  2025-01-01_00-28-40  [.jpg.xmp, _01.jpg.xmp, _001.jpg, _001.jpg.xmp...   \n",
       "1  2025-01-01_00-28-55  [.jpg.xmp, .jpg, _001.jpg, _001.jpg.xmp, _01.j...   \n",
       "2  2025-01-01_00-28-57  [_01.jpg.xmp, .jpg, _001.jpg.xmp, .jpg.xmp, _0...   \n",
       "3  2025-01-01_10-22-31                   [.dng.xmp, .jpg, .dng, .jpg.xmp]   \n",
       "4  2025-01-01_10-22-33                   [.jpg, .dng.xmp, .jpg.xmp, .dng]   \n",
       "5  2025-01-01_11-01-07                   [.dng, .jpg, .jpg.xmp, .dng.xmp]   \n",
       "6  2025-01-01_11-01-10                   [.jpg.xmp, .dng, .dng.xmp, .jpg]   \n",
       "7  2025-01-01_11-01-12                   [.dng, .jpg.xmp, .jpg, .dng.xmp]   \n",
       "8  2025-01-01_11-01-13                   [.dng.xmp, .jpg.xmp, .dng, .jpg]   \n",
       "9  2025-01-01_11-06-48  [.jpg, _01.jpg.xmp, _001.jpg.xmp, _001.jpg, .j...   \n",
       "\n",
       "   file_count subdirectory  \n",
       "0           5   2025\\01\\01  \n",
       "1           5   2025\\01\\01  \n",
       "2           5   2025\\01\\01  \n",
       "3           4   2025\\01\\01  \n",
       "4           4   2025\\01\\01  \n",
       "5           4   2025\\01\\01  \n",
       "6           4   2025\\01\\01  \n",
       "7           4   2025\\01\\01  \n",
       "8           4   2025\\01\\01  \n",
       "9           5   2025\\01\\01  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a more sophisticated grouping that handles suffixes before extensions\n",
    "# For example: \"2025-01-01_00-28-40.jpg\" and \"2025-01-01_00-28-40_001.jpg\"\n",
    "# should be grouped under base \"2025-01-01_00-28-40\"\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "image_groups = defaultdict(list)\n",
    "\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    for file_path in target_dir.iterdir():\n",
    "        if file_path.is_file():\n",
    "            filename = file_path.name\n",
    "\n",
    "            # Extract the base name by removing extension and any suffix pattern\n",
    "            # Pattern: basename[_suffix].extension[.extension]\n",
    "            # Example: \"2025-01-01_00-28-40_001.jpg.xmp\" -> base: \"2025-01-01_00-28-40\"\n",
    "\n",
    "            # First, remove all extensions (handle .jpg.xmp cases)\n",
    "            name_without_ext = filename\n",
    "            while '.' in name_without_ext:\n",
    "                name_without_ext = Path(name_without_ext).stem\n",
    "\n",
    "            # Check if there's a suffix pattern like _001, _002, etc.\n",
    "            # Look for underscore followed by digits at the end\n",
    "            match = re.match(r'^(.+?)(_\\d+)?$', name_without_ext)\n",
    "            base_name = match[1] if match else name_without_ext\n",
    "            # Calculate the suffix (everything after base_name)\n",
    "            suffix = filename[len(base_name):]\n",
    "\n",
    "            image_groups[base_name].append({\n",
    "                'file_path': file_path,\n",
    "                'suffix': suffix\n",
    "            })\n",
    "\n",
    "# Create DataFrame with one row per image\n",
    "image_data = []\n",
    "\n",
    "for base_name, files_info in sorted(image_groups.items()):\n",
    "    # Get all suffixes\n",
    "    suffixes = [info['suffix'] for info in files_info]\n",
    "\n",
    "    # Get file paths\n",
    "    file_paths = [info['file_path'] for info in files_info]\n",
    "\n",
    "    # Get relative subdirectory\n",
    "    rel_subdir = file_paths[0].parent.relative_to(photos_root)\n",
    "\n",
    "    image_data.append({\n",
    "        'base_name': base_name,\n",
    "        'suffixes': suffixes,\n",
    "        'file_count': len(suffixes),\n",
    "        'subdirectory': str(rel_subdir)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df_images = pd.DataFrame(image_data)\n",
    "\n",
    "print(f\"Created image DataFrame with {len(df_images)} unique images\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df_images.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
