{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox Notebook\n",
    "\n",
    "Experimental notebook for testing `home_media` package functionality.\n",
    "\n",
    "Auto-reload is enabled to pick up changes to the package without restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload for the home_media package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path so we can import home_media\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import home_media package\n",
    "from home_media import (\n",
    "    scan_directory,\n",
    "    group_files_to_images,\n",
    "    extract_base_name,\n",
    "    Image,\n",
    "    ImageFile,\n",
    "    FileRole,\n",
    "    FileFormat,\n",
    ")\n",
    "from home_media.scanner import list_subdirectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config from config.yaml\n",
    "config_path = Path.cwd().parent / \"config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "photos_root = Path(config['photos_root_original'])\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"photos_root_original: {photos_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Subdirectories in photos_root_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use home_media to list subdirectories\n",
    "subdirs = list_subdirectories(photos_root)\n",
    "\n",
    "print(f\"Found {len(subdirs)} subdirectories in: {photos_root}\\n\")\n",
    "\n",
    "for subdir in subdirs[:20]:  # Show first 20\n",
    "    print(f\"  ðŸ“ {subdir.name}\")\n",
    "\n",
    "if len(subdirs) > 20:\n",
    "    print(f\"\\n  ... and {len(subdirs) - 20} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan a Specific Subdirectory\n",
    "\n",
    "Let's examine a specific subdirectory to see what images and files we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subdirectory to examine\n",
    "subdir = \"2025/01/01\"\n",
    "target_dir = photos_root / subdir\n",
    "\n",
    "print(f\"Scanning directory: {target_dir}\")\n",
    "print(f\"Relative path: {subdir}\")\n",
    "print()\n",
    "\n",
    "# Use home_media to scan and group files\n",
    "images_df, files_df = scan_directory(target_dir, photos_root=photos_root)\n",
    "\n",
    "print(f\"Found {len(images_df)} images with {len(files_df)} total files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images DataFrame\n",
    "\n",
    "One row per image (moment in time), with aggregated information about all its files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images DataFrame\n",
    "print(\"Images DataFrame:\")\n",
    "print(f\"Columns: {list(images_df.columns)}\\n\")\n",
    "\n",
    "# Show first 10 images\n",
    "images_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Image Statistics:\\n\")\n",
    "print(f\"Total images: {len(images_df)}\")\n",
    "print(f\"Images with RAW files: {images_df['has_raw'].sum()}\")\n",
    "print(f\"Images with JPEG files: {images_df['has_jpeg'].sum()}\")\n",
    "print(f\"Images with sidecars: {images_df['has_sidecar'].sum()}\")\n",
    "print(f\"\\nAverage files per image: {images_df['file_count'].mean():.1f}\")\n",
    "print(f\"Max files per image: {images_df['file_count'].max()}\")\n",
    "print(f\"\\nTotal storage: {images_df['total_size_bytes'].sum() / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files DataFrame\n",
    "\n",
    "One row per file, linked to images by `base_name` and `subdirectory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display files DataFrame\n",
    "print(\"Files DataFrame:\")\n",
    "print(f\"Columns: {list(files_df.columns)}\\n\")\n",
    "\n",
    "# Show first 10 files\n",
    "files_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File format breakdown\n",
    "print(\"File Format Distribution:\\n\")\n",
    "format_counts = files_df['format'].value_counts()\n",
    "for format_type, count in format_counts.items():\n",
    "    print(f\"  {format_type}: {count}\")\n",
    "\n",
    "print(\"\\nFile Role Distribution:\\n\")\n",
    "role_counts = files_df['role'].value_counts()\n",
    "for role, count in role_counts.items():\n",
    "    print(f\"  {role}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Image Objects\n",
    "\n",
    "For more complex operations, we can work with the `Image` objects directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths and group into Image objects\n",
    "file_paths = [f for f in target_dir.iterdir() if f.is_file()]\n",
    "images = group_files_to_images(file_paths, photos_root=photos_root)\n",
    "\n",
    "print(f\"Created {len(images)} Image objects\\n\")\n",
    "\n",
    "# Examine the first image in detail\n",
    "if images:\n",
    "    img = images[0]\n",
    "    print(f\"Image: {img.base_name}\")\n",
    "    print(f\"  Subdirectory: {img.subdirectory}\")\n",
    "    print(f\"  File count: {img.file_count}\")\n",
    "    print(f\"  Has RAW: {img.has_raw}\")\n",
    "    print(f\"  Has JPEG: {img.has_jpeg}\")\n",
    "    print(f\"  Has sidecar: {img.has_sidecar}\")\n",
    "    print(f\"  Total size: {img.total_size_bytes:,} bytes\")\n",
    "    print(f\"  Suffixes: {img.suffixes}\")\n",
    "    print(f\"\\n  Files:\")\n",
    "    for f in img.files:\n",
    "        print(f\"    - {f.filename}\")\n",
    "        print(f\"      Role: {f.role.name}, Format: {f.format.value}, Size: {f.file_size_bytes:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filename Pattern Analysis\n",
    "\n",
    "Let's see how the `extract_base_name()` function handles different filename patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different filename patterns\n",
    "test_filenames = [\n",
    "    \"2025-01-01_00-28-40.jpg\",\n",
    "    \"2025-01-01_00-28-40.CR3\",\n",
    "    \"2025-01-01_00-28-40_001.jpg\",\n",
    "    \"2025-01-01_00-28-40.jpg.xmp\",\n",
    "    \"PXL_20251210_200246684.RAW-01.COVER.jpg\",\n",
    "    \"PXL_20251210_200246684.RAW-02.ORIGINAL.dng\",\n",
    "    \"photo_edit.jpg\",\n",
    "]\n",
    "\n",
    "print(\"Filename Pattern Analysis:\\n\")\n",
    "for filename in test_filenames:\n",
    "    base_name, suffix = extract_base_name(filename)\n",
    "    print(f\"{filename}\")\n",
    "    print(f\"  base_name: {base_name}\")\n",
    "    print(f\"  suffix: {suffix}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images with Multiple Files\n",
    "\n",
    "Find images that have multiple files (RAW+JPEG pairs, sidecars, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images with multiple files\n",
    "multi_file_images = images_df[images_df['file_count'] > 1]\n",
    "\n",
    "print(f\"Images with multiple files: {len(multi_file_images)} of {len(images_df)}\\n\")\n",
    "\n",
    "# Show examples\n",
    "print(\"Examples:\")\n",
    "for idx, row in multi_file_images.head(5).iterrows():\n",
    "    print(f\"\\n{row['base_name']}:\")\n",
    "    print(f\"  Files: {row['file_count']}\")\n",
    "    print(f\"  Suffixes: {row['suffixes']}\")\n",
    "    print(f\"  Has RAW: {row['has_raw']}, Has JPEG: {row['has_jpeg']}, Has sidecar: {row['has_sidecar']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Naming Preview\n",
    "\n",
    "Preview how files would be renamed using the canonical naming scheme: `YYYY/mm/dd/YYYY-mm-dd_HH-MM-SS` + suffix.\n",
    "\n",
    "In the future, the capture time will be extracted from EXIF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview canonical naming for the first image\n",
    "if images:\n",
    "    img = images[0]\n",
    "\n",
    "    # Simulate EXIF capture time (in real use, this comes from EXIF)\n",
    "    # Try to parse from the base_name if it follows our standard format\n",
    "    try:\n",
    "        # Try to parse datetime from base_name like \"2025-01-01_00-28-40\"\n",
    "        if len(img.base_name) >= 19 and img.base_name[10] == '_':\n",
    "            simulated_capture_time = datetime.strptime(img.base_name[:19], \"%Y-%m-%d_%H-%M-%S\")\n",
    "        else:\n",
    "            simulated_capture_time = datetime(2025, 1, 1, 0, 28, 40)\n",
    "    except Exception:\n",
    "        simulated_capture_time = datetime(2025, 1, 1, 0, 28, 40)\n",
    "\n",
    "    print(\"Current naming:\")\n",
    "    print(f\"  Base name: {img.base_name}\")\n",
    "    print(f\"  Subdirectory: {img.subdirectory}\")\n",
    "    print(f\"  Files: {img.file_count}\")\n",
    "\n",
    "    print(f\"\\nCanonical naming (based on capture time: {simulated_capture_time}):\")\n",
    "    print(f\"  Base name: {img.get_canonical_name(simulated_capture_time)}\")\n",
    "    print(f\"  Subdirectory: {img.get_canonical_subdirectory(simulated_capture_time)}\")\n",
    "\n",
    "    print(f\"\\nFull canonical paths would be:\")\n",
    "    for f in img.files:\n",
    "        canonical_path = (\n",
    "            f\"{img.get_canonical_subdirectory(simulated_capture_time)}/\"\n",
    "            f\"{img.get_canonical_name(simulated_capture_time)}{f.suffix}\"\n",
    "        )\n",
    "        print(f\"  {canonical_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Examples\n",
    "\n",
    "Use pandas to query the data in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find images that only have RAW files (no JPEG)\n",
    "raw_only = images_df[(images_df['has_raw']) & (~images_df['has_jpeg'])]\n",
    "print(f\"Images with only RAW (no JPEG): {len(raw_only)}\")\n",
    "raw_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find images with XMP sidecars\n",
    "with_sidecar = images_df[images_df['has_sidecar']]\n",
    "print(f\"Images with XMP sidecars: {len(with_sidecar)}\")\n",
    "with_sidecar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CR3 (Canon RAW) files\n",
    "cr3_files = files_df[files_df['format'] == 'cr3']\n",
    "print(f\"Canon RAW (CR3) files: {len(cr3_files)}\")\n",
    "cr3_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest images by total size\n",
    "largest_images = images_df.nlargest(10, 'total_size_bytes')[['base_name', 'file_count', 'total_size_bytes']]\n",
    "largest_images['size_mb'] = largest_images['total_size_bytes'] / (1024**2)\n",
    "print(\"Largest images by total size:\\n\")\n",
    "largest_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
