{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Development Session for home_media_ai\n",
    "\n",
    "This notebook provides a live development environment with auto-reload enabled.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Select Python Kernel**: In VSCode, click on the kernel picker in the top-right corner and select your Python environment where `home_media_ai` is installed.\n",
    "\n",
    "2. **Run the Auto-Reload Cell**: Execute the first code cell below to enable auto-reload. This will automatically reload modules when you make changes to the source code.\n",
    "\n",
    "3. **Import Your Package**: Import the modules you want to work with from `home_media_ai`.\n",
    "\n",
    "4. **Develop & Test**: Make changes to your source files in `src/python/home_media_ai/`, and the changes will be automatically reloaded when you re-run cells.\n",
    "\n",
    "## How Auto-Reload Works\n",
    "\n",
    "- `%load_ext autoreload` - Loads the IPython autoreload extension\n",
    "- `%autoreload 2` - Reloads all modules automatically before executing code\n",
    "- This means you can edit functions in your package and test them immediately without restarting the kernel\n",
    "\n",
    "## Development Workflow\n",
    "\n",
    "1. Import and test functionality in this notebook\n",
    "2. When you find bugs or want to add features, edit the source files\n",
    "3. Re-run the cells to see your changes\n",
    "4. Once the code is working well, it's already in the package and ready to use!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload for live development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Auto-reload enabled! Changes to source files will be automatically reloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package and commonly used modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the package to the path if needed\n",
    "package_root = Path().resolve().parent\n",
    "if str(package_root) not in sys.path:\n",
    "    sys.path.insert(0, str(package_root))\n",
    "\n",
    "sys.path.insert(0, r\"E:\\programming\\hydra-image-processor\\src\\Python\")\n",
    "\n",
    "# Import home_media_ai modules\n",
    "from home_media_ai import Media, MediaType, MediaQuery\n",
    "from home_media_ai.config import get_config, get_path_resolver, Config\n",
    "from home_media_ai.io import read_image_as_array, read_image_metadata\n",
    "\n",
    "# Import other useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import hydra_image_processor as Hydra\n",
    "\n",
    "print(f\"Package root: {package_root}\")\n",
    "print(\"Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection Setup\n",
    "\n",
    "Connect to the database using configuration from `config.yaml` (or environment variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = get_config()\n",
    "print(f\"Database URI: {config.database.uri}\")\n",
    "print(f\"Storage roots: {config.storage_roots}\")\n",
    "\n",
    "# Create database connection\n",
    "if config.database.uri:\n",
    "    engine = create_engine(config.database.uri)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    print(\"Database connection established!\")\n",
    "else:\n",
    "    print(\"No database URI configured. Set in config.yaml or HOME_MEDIA_AI_URI environment variable.\")\n",
    "    session = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 5-Star Canon Images from 2024\n",
    "\n",
    "Let's find all 5-star rated images from 2024 taken with Canon cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session:\n",
    "    # Query for 5-star Canon images from 2024\n",
    "    query = session.query(Media).filter(\n",
    "        Media.rating  >= 4,\n",
    "        Media.created >= datetime(2024, 1, 1),\n",
    "        Media.created <  datetime(2025, 1, 1),\n",
    "        Media.is_original == True,\n",
    "        Media.camera_make.like(\"%Canon%\"),\n",
    "    )\n",
    "\n",
    "    results = query.all()\n",
    "\n",
    "    print(f\"Found {len(results)} 5-star Canon images from 2024\")\n",
    "\n",
    "    if results:\n",
    "        # Display info about the first few\n",
    "        print(\"\\nFirst 5 results:\")\n",
    "        for i, media in enumerate(results[:5]):\n",
    "            print(f\"\\n{i+1}. {media.filename}\")\n",
    "            print(f\"   Camera: {media.camera_make} {media.camera_model}\")\n",
    "            print(f\"   Date: {media.created}\")\n",
    "            print(f\"   Size: {media.width}x{media.height}\")\n",
    "            print(f\"   Type: {media.media_type.name}\")\n",
    "            print(f\"   Path: {media.get_full_path()}\")\n",
    "    else:\n",
    "        print(\"No matching images found. Try adjusting the filters.\")\n",
    "else:\n",
    "    print(\"Session not available. Configure database connection first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display One of the 5-Star Images\n",
    "\n",
    "Use the new `read_as_array()` method to load and display an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session and results:\n",
    "    # Select the first result\n",
    "    selected_media = results[0]\n",
    "\n",
    "    print(f\"Loading: {selected_media.filename}\")\n",
    "    print(f\"Camera: {selected_media.camera_make} {selected_media.camera_model}\")\n",
    "    print(f\"Date: {selected_media.created}\")\n",
    "    print(f\"Resolution: {selected_media.width}x{selected_media.height}\")\n",
    "    print(f\"Rating: {'⭐' * selected_media.rating}\")\n",
    "\n",
    "    try:\n",
    "        # Use the new convenience method to read the image\n",
    "        img_array = selected_media.read_as_array()\n",
    "\n",
    "        print(f\"\\nImage loaded successfully!\")\n",
    "        print(f\"Array shape: {img_array.shape}\")\n",
    "        print(f\"Data type: {img_array.dtype}\")\n",
    "        print(f\"Value range: [{img_array.min()}, {img_array.max()}]\")\n",
    "\n",
    "        # Display the image\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # Convert to appropriate display range if needed\n",
    "        if img_array.dtype == np.uint16:\n",
    "            # For 16-bit images, normalize to 8-bit for display\n",
    "            display_img = (img_array / 256).astype(np.uint8)\n",
    "        else:\n",
    "            display_img = img_array\n",
    "\n",
    "        plt.imshow(display_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{selected_media.filename}\\n{selected_media.camera_make} {selected_media.camera_model} - {selected_media.created.strftime('%Y-%m-%d')}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nError: Could not find the file at resolved path.\")\n",
    "        print(f\"Expected path: {selected_media.get_full_path()}\")\n",
    "        print(f\"\\nThis might mean you need to update your config.yaml storage_roots mapping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError loading image: {e}\")\n",
    "else:\n",
    "    print(\"No images to display. Run the query cell above first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_uint8 = (img_array / 256).astype(np.uint8)\n",
    "\n",
    "# display the converted image in three grayscale channels side by side\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_array_uint8[:, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Red Channel')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_array_uint8[:, :, 1], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Green Channel')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_array_uint8[:, :, 2], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Blue Channel')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_norm = img_array.astype(np.float32) / img_array.max()\n",
    "imL = Hydra.LoG(im_norm, [5,5,0])\n",
    "\n",
    "im_bright = imL < -1e-3\n",
    "im_dark   = imL > 1e-3\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(im_bright[:, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Red Channel Bright Edges')\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(im_bright[:, :, 1], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Green Channel Bright Edges')\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(im_bright[:, :, 2], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Blue Channel Bright Edges')\n",
    "plt.tight_layout()\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(im_dark[:, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Red Channel Dark Edges')\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(im_dark[:, :, 1], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Green Channel Dark Edges')\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(im_dark[:, :, 2], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Blue Channel Dark Edges')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT Bandpass Filtering\n",
    "\n",
    "Create bandpass filtered images using FFT for different frequency bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circular_bandpass_mask(shape, inner_radius, outer_radius):\n",
    "    \"\"\"\n",
    "    Create a circular bandpass mask for FFT frequency filtering.\n",
    "\n",
    "    Args:\n",
    "        shape: Tuple of (height, width) for the mask\n",
    "        inner_radius: Inner radius of the band (low frequencies to block)\n",
    "        outer_radius: Outer radius of the band (high frequencies to block)\n",
    "\n",
    "    Returns:\n",
    "        Binary mask with 1s in the band and 0s elsewhere\n",
    "    \"\"\"\n",
    "    rows, cols = shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "\n",
    "    # Create coordinate grids centered at the middle\n",
    "    y, x = np.ogrid[:rows, :cols]\n",
    "\n",
    "    # Calculate distance from center for each point\n",
    "    distance = np.sqrt((x - ccol)**2 + (y - crow)**2)\n",
    "\n",
    "    # Create bandpass mask (1 in the band, 0 outside)\n",
    "    mask = ((distance >= inner_radius) & (distance <= outer_radius)).astype(np.float32)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_bandpass_fft(image_channel, inner_radius, outer_radius):\n",
    "    \"\"\"\n",
    "    Apply bandpass filter using FFT to a single channel.\n",
    "\n",
    "    Args:\n",
    "        image_channel: 2D numpy array (single channel)\n",
    "        inner_radius: Inner radius of bandpass filter\n",
    "        outer_radius: Outer radius of bandpass filter\n",
    "\n",
    "    Returns:\n",
    "        Filtered image channel\n",
    "    \"\"\"\n",
    "    # Compute FFT and shift zero frequency to center\n",
    "    fft = np.fft.fft2(image_channel)\n",
    "    fft_shifted = np.fft.fftshift(fft)\n",
    "\n",
    "    # Create and apply bandpass mask\n",
    "    mask = create_circular_bandpass_mask(image_channel.shape, inner_radius, outer_radius)\n",
    "    mask = Hydra.gaussian(mask, [25,25,0])  # Smooth the mask edges\n",
    "    fft_filtered = fft_shifted * mask\n",
    "\n",
    "    # Inverse FFT\n",
    "    fft_ishifted = np.fft.ifftshift(fft_filtered)\n",
    "    filtered_channel = np.fft.ifft2(fft_ishifted)\n",
    "    filtered_channel = np.abs(filtered_channel)\n",
    "\n",
    "    return filtered_channel, fft_shifted, mask\n",
    "\n",
    "\n",
    "# Use the normalized image (im_norm from earlier)\n",
    "if 'im_norm' in locals():\n",
    "    test_img = im_norm\n",
    "\n",
    "    # Resize for faster processing if image is very large\n",
    "    if test_img.shape[0] > 10000 or test_img.shape[1] > 10000:\n",
    "        # Downsample for faster FFT processing\n",
    "        scale_factor = 1000 / max(test_img.shape[0], test_img.shape[1])\n",
    "        new_height = int(test_img.shape[0] * scale_factor)\n",
    "        new_width = int(test_img.shape[1] * scale_factor)\n",
    "        from scipy.ndimage import zoom\n",
    "        test_img = zoom(test_img, (scale_factor, scale_factor, 1), order=1)\n",
    "        print(f\"Resized to {test_img.shape} for faster processing\")\n",
    "\n",
    "    # Define frequency bands (inner_radius, outer_radius)\n",
    "    # Radius is in pixels from the center of the FFT\n",
    "    max_radius = min(test_img.shape[0], test_img.shape[1]) // 2\n",
    "\n",
    "    bands = [\n",
    "        (0,   8, \"Very Low Freq\\n(Large structures)\"),\n",
    "        (8,  16, \"Low Freq\\n(Coarse details)\"),\n",
    "        (16, 32, \"Mid Freq\\n(Fine details)\"),\n",
    "        (32, max_radius, \"High Freq\\n(Edges/Noise)\"),\n",
    "    ]\n",
    "\n",
    "    # Process each channel through all bands\n",
    "    num_bands = len(bands)\n",
    "    num_channels = 3\n",
    "    channel_names = ['Red', 'Green', 'Blue']\n",
    "\n",
    "    # Create comprehensive figure\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "    # Original image\n",
    "    ax = plt.subplot(num_channels + 2, num_bands + 1, 1)\n",
    "    ax.imshow(np.clip(test_img, 0, 1))  # Clip for display\n",
    "    ax.set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Process each channel\n",
    "    for ch_idx in range(num_channels):\n",
    "        channel = test_img[:, :, ch_idx].astype(np.float32)\n",
    "\n",
    "        # Compute FFT for visualization (full spectrum)\n",
    "        fft_full = np.fft.fft2(channel)\n",
    "        fft_shifted_full = np.fft.fftshift(fft_full)\n",
    "        magnitude_spectrum = np.log(np.abs(fft_shifted_full) + 1)\n",
    "\n",
    "        # Show FFT magnitude spectrum for this channel\n",
    "        ax = plt.subplot(num_channels + 2, num_bands + 1, (ch_idx + 1) * (num_bands + 1) + 1)\n",
    "        ax.imshow(magnitude_spectrum, cmap='hot')\n",
    "        ax.set_title(f'{channel_names[ch_idx]} FFT\\nMagnitude', fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Process each frequency band\n",
    "        for band_idx, (inner_r, outer_r, band_name) in enumerate(bands):\n",
    "            filtered, fft_shift, mask = apply_bandpass_fft(channel, inner_r, outer_r)\n",
    "\n",
    "            # Normalize filtered image for display\n",
    "            filtered_norm = filtered.copy()\n",
    "            if filtered_norm.max() > filtered_norm.min():\n",
    "                filtered_norm = (filtered_norm - filtered_norm.min()) / (filtered_norm.max() - filtered_norm.min())\n",
    "\n",
    "            # Plot position\n",
    "            plot_idx = (ch_idx + 1) * (num_bands + 1) + band_idx + 2\n",
    "            ax = plt.subplot(num_channels + 2, num_bands + 1, plot_idx)\n",
    "            ax.imshow(filtered_norm, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "            if ch_idx == 0:\n",
    "                ax.set_title(band_name, fontsize=10, fontweight='bold')\n",
    "            if band_idx == 0:\n",
    "                ax.set_ylabel(channel_names[ch_idx], fontsize=10)\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Add frequency band masks visualization in bottom row\n",
    "    for band_idx, (inner_r, outer_r, band_name) in enumerate(bands):\n",
    "        mask = create_circular_bandpass_mask(test_img[:, :, 0].shape, inner_r, outer_r)\n",
    "\n",
    "        ax = plt.subplot(num_channels + 2, num_bands + 1,\n",
    "                        (num_channels + 1) * (num_bands + 1) + band_idx + 2)\n",
    "        ax.imshow(mask, cmap='gray')\n",
    "        ax.set_title(f'Mask\\n({inner_r}-{outer_r}px)', fontsize=9)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('FFT Bandpass Filtering - Frequency Domain Analysis',\n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image shape: {test_img.shape}\")\n",
    "    print(f\"Max radius: {max_radius} pixels\")\n",
    "    print(f\"\\nFrequency bands:\")\n",
    "    for inner_r, outer_r, name in bands:\n",
    "        print(f\"  {name.replace(chr(10), ' ')}: {inner_r}-{outer_r} pixels from center\")\n",
    "\n",
    "else:\n",
    "    print(\"Please run the image loading cells first to create 'im_norm' variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session and results:\n",
    "    # Select a different image if available\n",
    "    selected_index = min(1, len(results) - 1)  # Get second image or first if only one\n",
    "    selected_media = results[selected_index]\n",
    "\n",
    "    try:\n",
    "        img_array = selected_media.read_as_array()\n",
    "\n",
    "        # Prepare display\n",
    "        if img_array.dtype == np.uint16:\n",
    "            display_img = (img_array / 256).astype(np.uint8)\n",
    "        else:\n",
    "            display_img = img_array\n",
    "\n",
    "        # Create figure with metadata\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), gridspec_kw={'width_ratios': [3, 1]})\n",
    "\n",
    "        # Display image\n",
    "        ax1.imshow(display_img)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(selected_media.filename, fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Display metadata\n",
    "        ax2.axis('off')\n",
    "        metadata_text = f\"\"\"\n",
    "METADATA\n",
    "━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Camera\n",
    "{selected_media.camera_make}\n",
    "{selected_media.camera_model}\n",
    "\n",
    "Lens\n",
    "{selected_media.lens_model or 'Unknown'}\n",
    "\n",
    "Date\n",
    "{selected_media.created.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Rating\n",
    "{'*' * selected_media.rating}\n",
    "\n",
    "Dimensions\n",
    "{selected_media.width} × {selected_media.height}\n",
    "\n",
    "File Size\n",
    "{selected_media.file_size / 1024 / 1024:.2f} MB\n",
    "\n",
    "Format\n",
    "{selected_media.media_type.name.upper()}\n",
    "{selected_media.file_ext.upper()}\n",
    "        \"\"\"\n",
    "\n",
    "        if selected_media.gps_latitude and selected_media.gps_longitude:\n",
    "            metadata_text += f\"\"\"\n",
    "Location\n",
    "{selected_media.gps_latitude:.6f}°\n",
    "{selected_media.gps_longitude:.6f}°\n",
    "            \"\"\"\n",
    "\n",
    "        ax2.text(0.1, 0.95, metadata_text,\n",
    "                transform=ax2.transAxes,\n",
    "                fontsize=10,\n",
    "                verticalalignment='top',\n",
    "                fontfamily='monospace')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not find file: {selected_media.get_full_path()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test New Helper Functions\n",
    "\n",
    "Try out the new utility functions and IO capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test utility functions\n",
    "from home_media_ai.utils import (\n",
    "    infer_media_type_from_extension,\n",
    "    calculate_file_hash,\n",
    "    split_file_path,\n",
    "    validate_file_extension\n",
    ")\n",
    "\n",
    "# Test extension inference\n",
    "print(\"Media type inference:\")\n",
    "print(f\"  .jpg -> {infer_media_type_from_extension('.jpg')}\")\n",
    "print(f\"  .CR2 -> {infer_media_type_from_extension('.cr2')}\")\n",
    "print(f\"  .dng -> {infer_media_type_from_extension('.dng')}\")\n",
    "\n",
    "# Test path splitting\n",
    "print(\"\\nPath splitting:\")\n",
    "example_path = \"/volume1/photos/2024/October/IMG_001.CR2\"\n",
    "storage_root, directory, filename = split_file_path(example_path, storage_root=\"/volume1/photos\")\n",
    "print(f\"  Full path: {example_path}\")\n",
    "print(f\"  Storage root: {storage_root}\")\n",
    "print(f\"  Directory: {directory}\")\n",
    "print(f\"  Filename: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare RAW vs JPEG from Same Scene\n",
    "\n",
    "If you have RAW+JPEG pairs, compare their data types and value ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session:\n",
    "    # Find a RAW+JPEG pair (images with same timestamp)\n",
    "    from sqlalchemy import func\n",
    "    \n",
    "    # Find timestamps that have multiple media types\n",
    "    pairs_query = session.query(\n",
    "        Media.created,\n",
    "        func.count(Media.id).label('count')\n",
    "    ).filter(\n",
    "        Media.rating == 5,\n",
    "        Media.camera_make.like('%Canon%'),\n",
    "        Media.created >= datetime(2024, 1, 1)\n",
    "    ).group_by(Media.created).having(func.count(Media.id) > 1)\n",
    "    \n",
    "    pair_timestamps = [row[0] for row in pairs_query.limit(5).all()]\n",
    "    \n",
    "    if pair_timestamps:\n",
    "        # Get both RAW and JPEG from first matching timestamp\n",
    "        timestamp = pair_timestamps[0]\n",
    "        pair_media = session.query(Media).filter(Media.created == timestamp).all()\n",
    "        \n",
    "        if len(pair_media) >= 2:\n",
    "            print(f\"Found RAW+JPEG pair from {timestamp}\")\n",
    "            print(f\"Number of files: {len(pair_media)}\")\n",
    "            \n",
    "            for media in pair_media:\n",
    "                print(f\"\\n{media.filename} ({media.media_type.name}):\")\n",
    "                try:\n",
    "                    img = media.read_as_array()\n",
    "                    print(f\"  Shape: {img.shape}\")\n",
    "                    print(f\"  Dtype: {img.dtype}\")\n",
    "                    print(f\"  Range: [{img.min()}, {img.max()}]\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error: {e}\")\n",
    "    else:\n",
    "        print(\"No RAW+JPEG pairs found in the results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Close database connection when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session:\n",
    "    session.close()\n",
    "    print(\"Database session closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
